{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puOQpHMv6rO8",
        "outputId": "acd411c2-f900-49ed-a22d-45ba1fd33ab8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.1.3-py3-none-any.whl (135 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▍                             | 10 kB 20.7 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 20 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 30 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 40 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 61 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 81 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 92 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 135 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.9.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (7.9.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (1.21.6)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.0.10)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 43.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->keras-tuner) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2022.9.24)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (1.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (0.38.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (2.14.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (3.19.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (1.50.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.2)\n",
            "Installing collected packages: jedi, kt-legacy, keras-tuner\n",
            "Successfully installed jedi-0.18.2 keras-tuner-1.1.3 kt-legacy-1.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "r7-4e6zw6rO-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41d13a74-a26d-44d7-dda1-280d4a7ff6d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-719df02fc4dd>:5: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  import kerastuner as kt\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import kerastuner as kt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from kerastuner.tuners import Hyperband, BayesianOptimization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "vhsVCa0o6rPA",
        "outputId": "db16be21-820f-462e-f018-f4945718407b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       STATUS   ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_T19  \\\n",
              "0           1      5000              1                     0   \n",
              "1           1      5000              0                     0   \n",
              "2           1      6692              1                     0   \n",
              "3           1    142590              1                     0   \n",
              "4           1      5000              1                     0   \n",
              "...       ...       ...            ...                   ...   \n",
              "34293       1      5000              0                     0   \n",
              "34294       1      5000              0                     0   \n",
              "34295       1      5000              0                     0   \n",
              "34296       1      5000              1                     0   \n",
              "34297       1  36500179              0                     0   \n",
              "\n",
              "       APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  \\\n",
              "0                        0                    0                    0   \n",
              "1                        0                    0                    1   \n",
              "2                        1                    0                    0   \n",
              "3                        1                    0                    0   \n",
              "4                        1                    0                    0   \n",
              "...                    ...                  ...                  ...   \n",
              "34293                    0                    1                    0   \n",
              "34294                    0                    1                    0   \n",
              "34295                    1                    0                    0   \n",
              "34296                    0                    0                    1   \n",
              "34297                    1                    0                    0   \n",
              "\n",
              "       APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  APPLICATION_TYPE_T8  ...  \\\n",
              "0                        0                    0                    0  ...   \n",
              "1                        0                    0                    0  ...   \n",
              "2                        0                    0                    0  ...   \n",
              "3                        0                    0                    0  ...   \n",
              "4                        0                    0                    0  ...   \n",
              "...                    ...                  ...                  ...  ...   \n",
              "34293                    0                    0                    0  ...   \n",
              "34294                    0                    0                    0  ...   \n",
              "34295                    0                    0                    0  ...   \n",
              "34296                    0                    0                    0  ...   \n",
              "34297                    0                    0                    0  ...   \n",
              "\n",
              "       ORGANIZATION_Trust  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  \\\n",
              "0                       0                  0                       0   \n",
              "1                       0                  0                       0   \n",
              "2                       1                  0                       1   \n",
              "3                       1                  0                       0   \n",
              "4                       1                  0                       0   \n",
              "...                   ...                ...                     ...   \n",
              "34293                   0                  0                       0   \n",
              "34294                   0                  0                       0   \n",
              "34295                   0                  0                       0   \n",
              "34296                   0                  0                       0   \n",
              "34297                   0                  0                       0   \n",
              "\n",
              "       INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  \\\n",
              "0                             0                   0                 0   \n",
              "1                             0                   0                 0   \n",
              "2                             0                   0                 0   \n",
              "3                             1                   0                 0   \n",
              "4                             0                   0                 0   \n",
              "...                         ...                 ...               ...   \n",
              "34293                         0                   0                 0   \n",
              "34294                         0                   0                 0   \n",
              "34295                         0                   0                 0   \n",
              "34296                         0                   0                 0   \n",
              "34297                         0                   0                 1   \n",
              "\n",
              "       INCOME_AMT_25000-99999  INCOME_AMT_50M+  INCOME_AMT_5M-10M  \\\n",
              "0                           0                0                  0   \n",
              "1                           0                0                  0   \n",
              "2                           0                0                  0   \n",
              "3                           0                0                  0   \n",
              "4                           0                0                  0   \n",
              "...                       ...              ...                ...   \n",
              "34293                       0                0                  0   \n",
              "34294                       0                0                  0   \n",
              "34295                       0                0                  0   \n",
              "34296                       0                0                  0   \n",
              "34297                       0                0                  0   \n",
              "\n",
              "       SPECIAL_CONSIDERATIONS_Y  \n",
              "0                             0  \n",
              "1                             0  \n",
              "2                             0  \n",
              "3                             0  \n",
              "4                             0  \n",
              "...                         ...  \n",
              "34293                         0  \n",
              "34294                         0  \n",
              "34295                         0  \n",
              "34296                         0  \n",
              "34297                         0  \n",
              "\n",
              "[34298 rows x 37 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d3018c1-0fed-43c0-9f5f-a18b71da3b0b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STATUS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "      <th>APPLICATION_TYPE_T19</th>\n",
              "      <th>APPLICATION_TYPE_T3</th>\n",
              "      <th>APPLICATION_TYPE_T4</th>\n",
              "      <th>APPLICATION_TYPE_T5</th>\n",
              "      <th>APPLICATION_TYPE_T6</th>\n",
              "      <th>APPLICATION_TYPE_T7</th>\n",
              "      <th>APPLICATION_TYPE_T8</th>\n",
              "      <th>...</th>\n",
              "      <th>ORGANIZATION_Trust</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34293</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34294</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34295</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34296</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34297</th>\n",
              "      <td>1</td>\n",
              "      <td>36500179</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34298 rows × 37 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d3018c1-0fed-43c0-9f5f-a18b71da3b0b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6d3018c1-0fed-43c0-9f5f-a18b71da3b0b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6d3018c1-0fed-43c0-9f5f-a18b71da3b0b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# df = pd.read_csv('Resources/funding_processed.csv')\n",
        "df = pd.read_csv('funding_processed.csv')\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "T5C-v5dR6rPB"
      },
      "outputs": [],
      "source": [
        "def split_data(data, X, y, seed=5):\n",
        "    \"\"\"splits feature and target data into test and train sets and scales feature data\n",
        "\n",
        "    Args:\n",
        "        model (class): model class name\n",
        "        X (array): array containing feature column values\n",
        "        y (1D array): array containing target variable\n",
        "        seed (int): random seed value; default=5\n",
        "    \"\"\"\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seed)\n",
        "    scaler = StandardScaler().fit(X_train)\n",
        "    X_train_scaled = scaler.transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    \n",
        "    return X_train, X_test, y_train, y_test, X_train_scaled, X_test_scaled\n",
        "\n",
        "def make_model(hp):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    \n",
        "    hp_activation = hp.Choice('activation', ['relu'])\n",
        "    \n",
        "    \n",
        "    model.add(Dense(units = hp.Int('first_dense', min_value=2, max_value=36),\n",
        "                    activation = hp_activation,\n",
        "                    input_dim=36\n",
        "    ))\n",
        "    \n",
        "    for i in range(hp.Int('n_hidden', 1, 2)):\n",
        "        model.add(Dense(units=hp.Int('dense_' + str(i), min_value=1, max_value=9),\n",
        "                        activation=hp_activation\n",
        "    ))\n",
        "        \n",
        "        model.add(Dropout(hp.Choice('dropout_' + str(i), [0.0, 0.01, 0.1])\n",
        "    ))\n",
        "\n",
        "    \n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "    \n",
        "    hp_learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2)\n",
        "\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=Adam(learning_rate = hp_learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "I5jzA7HB6rPC"
      },
      "outputs": [],
      "source": [
        "#split preprocessed data into features and target arrays\n",
        "X = df.drop(columns=['IS_SUCCESSFUL'])\n",
        "#target array\n",
        "y = df['IS_SUCCESSFUL'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TAnJ6Sov6rPD"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test, X_train_scaled, X_test_scaled = split_data(df,X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR8s-pwX6rPD",
        "outputId": "9007376a-cdf1-488d-feaf-f3fdf67f6710"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25723, 36)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "X_train_scaled.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_LnRWA86rPE"
      },
      "outputs": [],
      "source": [
        "tuner = BayesianOptimization(\n",
        "    hypermodel = make_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=30,\n",
        "    num_initial_points=10,\n",
        "    seed=5,\n",
        "    tune_new_entries=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Kxc-Wn6O6rPF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5f13b3e0-2bca-4456-c73e-3e723cfc9022"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 04m 00s]\n",
            "accuracy: 0.7359561324119568\n",
            "\n",
            "Best accuracy So Far: 0.7362282872200012\n",
            "Total elapsed time: 00h 08m 35s\n",
            "\n",
            "Search: Running Trial #4\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "relu              |relu              |activation\n",
            "27                |19                |first_dense\n",
            "1                 |1                 |n_hidden\n",
            "7                 |2                 |dense_0\n",
            "0.1               |0                 |dropout_0\n",
            "0.0012183         |0.0036791         |learning_rate\n",
            "5                 |None              |dense_1\n",
            "0.1               |None              |dropout_1\n",
            "\n",
            "Epoch 1/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5911 - accuracy: 0.7035 - val_loss: 0.5669 - val_accuracy: 0.7223\n",
            "Epoch 2/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7228 - val_loss: 0.5635 - val_accuracy: 0.7231\n",
            "Epoch 3/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5613 - accuracy: 0.7245 - val_loss: 0.5597 - val_accuracy: 0.7245\n",
            "Epoch 4/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5606 - accuracy: 0.7269 - val_loss: 0.5589 - val_accuracy: 0.7248\n",
            "Epoch 5/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5576 - accuracy: 0.7293 - val_loss: 0.5575 - val_accuracy: 0.7261\n",
            "Epoch 6/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5574 - accuracy: 0.7307 - val_loss: 0.5576 - val_accuracy: 0.7237\n",
            "Epoch 7/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5572 - accuracy: 0.7277 - val_loss: 0.5554 - val_accuracy: 0.7255\n",
            "Epoch 8/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5563 - accuracy: 0.7297 - val_loss: 0.5553 - val_accuracy: 0.7257\n",
            "Epoch 9/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5550 - accuracy: 0.7304 - val_loss: 0.5547 - val_accuracy: 0.7247\n",
            "Epoch 10/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5550 - accuracy: 0.7322 - val_loss: 0.5558 - val_accuracy: 0.7275\n",
            "Epoch 11/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5544 - accuracy: 0.7307 - val_loss: 0.5550 - val_accuracy: 0.7258\n",
            "Epoch 12/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5544 - accuracy: 0.7314 - val_loss: 0.5536 - val_accuracy: 0.7252\n",
            "Epoch 13/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5543 - accuracy: 0.7326 - val_loss: 0.5547 - val_accuracy: 0.7278\n",
            "Epoch 14/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5536 - accuracy: 0.7295 - val_loss: 0.5530 - val_accuracy: 0.7276\n",
            "Epoch 15/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5545 - accuracy: 0.7300 - val_loss: 0.5552 - val_accuracy: 0.7280\n",
            "Epoch 16/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5531 - accuracy: 0.7318 - val_loss: 0.5528 - val_accuracy: 0.7278\n",
            "Epoch 17/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5532 - accuracy: 0.7311 - val_loss: 0.5542 - val_accuracy: 0.7254\n",
            "Epoch 18/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5539 - accuracy: 0.7320 - val_loss: 0.5545 - val_accuracy: 0.7278\n",
            "Epoch 19/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5519 - accuracy: 0.7317 - val_loss: 0.5550 - val_accuracy: 0.7286\n",
            "Epoch 20/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5526 - accuracy: 0.7309 - val_loss: 0.5545 - val_accuracy: 0.7279\n",
            "Epoch 21/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5530 - accuracy: 0.7302 - val_loss: 0.5546 - val_accuracy: 0.7276\n",
            "Epoch 22/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5526 - accuracy: 0.7323 - val_loss: 0.5559 - val_accuracy: 0.7272\n",
            "Epoch 23/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5519 - accuracy: 0.7324 - val_loss: 0.5557 - val_accuracy: 0.7282\n",
            "Epoch 24/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5512 - accuracy: 0.7321 - val_loss: 0.5534 - val_accuracy: 0.7284\n",
            "Epoch 25/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5521 - accuracy: 0.7322 - val_loss: 0.5540 - val_accuracy: 0.7259\n",
            "Epoch 26/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5519 - accuracy: 0.7326 - val_loss: 0.5549 - val_accuracy: 0.7264\n",
            "Epoch 27/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5518 - accuracy: 0.7325 - val_loss: 0.5560 - val_accuracy: 0.7271\n",
            "Epoch 28/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5511 - accuracy: 0.7312 - val_loss: 0.5564 - val_accuracy: 0.7264\n",
            "Epoch 29/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5508 - accuracy: 0.7325 - val_loss: 0.5536 - val_accuracy: 0.7261\n",
            "Epoch 30/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5519 - accuracy: 0.7314 - val_loss: 0.5553 - val_accuracy: 0.7277\n",
            "Epoch 31/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5516 - accuracy: 0.7330 - val_loss: 0.5540 - val_accuracy: 0.7269\n",
            "Epoch 32/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5512 - accuracy: 0.7327 - val_loss: 0.5538 - val_accuracy: 0.7279\n",
            "Epoch 33/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5495 - accuracy: 0.7318 - val_loss: 0.5550 - val_accuracy: 0.7266\n",
            "Epoch 34/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5499 - accuracy: 0.7330 - val_loss: 0.5560 - val_accuracy: 0.7264\n",
            "Epoch 35/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5494 - accuracy: 0.7320 - val_loss: 0.5539 - val_accuracy: 0.7265\n",
            "Epoch 36/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5512 - accuracy: 0.7318 - val_loss: 0.5538 - val_accuracy: 0.7264\n",
            "Epoch 37/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5495 - accuracy: 0.7331 - val_loss: 0.5561 - val_accuracy: 0.7282\n",
            "Epoch 38/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5503 - accuracy: 0.7325 - val_loss: 0.5539 - val_accuracy: 0.7272\n",
            "Epoch 39/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5497 - accuracy: 0.7330 - val_loss: 0.5541 - val_accuracy: 0.7265\n",
            "Epoch 40/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5493 - accuracy: 0.7328 - val_loss: 0.5558 - val_accuracy: 0.7277\n",
            "Epoch 41/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5492 - accuracy: 0.7326 - val_loss: 0.5550 - val_accuracy: 0.7273\n",
            "Epoch 42/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5498 - accuracy: 0.7328 - val_loss: 0.5576 - val_accuracy: 0.7265\n",
            "Epoch 43/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5496 - accuracy: 0.7346 - val_loss: 0.5574 - val_accuracy: 0.7294\n",
            "Epoch 44/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5505 - accuracy: 0.7335 - val_loss: 0.5548 - val_accuracy: 0.7258\n",
            "Epoch 45/100\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5495 - accuracy: 0.7328 - val_loss: 0.5555 - val_accuracy: 0.7273\n",
            "Epoch 46/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5512 - accuracy: 0.7347 - val_loss: 0.5549 - val_accuracy: 0.7261\n",
            "Epoch 47/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5487 - accuracy: 0.7327 - val_loss: 0.5559 - val_accuracy: 0.7277\n",
            "Epoch 48/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5485 - accuracy: 0.7342 - val_loss: 0.5570 - val_accuracy: 0.7268\n",
            "Epoch 49/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5494 - accuracy: 0.7335 - val_loss: 0.5546 - val_accuracy: 0.7261\n",
            "Epoch 50/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5486 - accuracy: 0.7331 - val_loss: 0.5543 - val_accuracy: 0.7277\n",
            "Epoch 51/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5478 - accuracy: 0.7356 - val_loss: 0.5549 - val_accuracy: 0.7276\n",
            "Epoch 52/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5495 - accuracy: 0.7334 - val_loss: 0.5553 - val_accuracy: 0.7278\n",
            "Epoch 53/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5498 - accuracy: 0.7339 - val_loss: 0.5568 - val_accuracy: 0.7262\n",
            "Epoch 54/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5485 - accuracy: 0.7332 - val_loss: 0.5559 - val_accuracy: 0.7277\n",
            "Epoch 55/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5490 - accuracy: 0.7349 - val_loss: 0.5547 - val_accuracy: 0.7291\n",
            "Epoch 56/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5493 - accuracy: 0.7338 - val_loss: 0.5561 - val_accuracy: 0.7280\n",
            "Epoch 57/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5474 - accuracy: 0.7342 - val_loss: 0.5562 - val_accuracy: 0.7287\n",
            "Epoch 58/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5487 - accuracy: 0.7340 - val_loss: 0.5561 - val_accuracy: 0.7280\n",
            "Epoch 59/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5486 - accuracy: 0.7338 - val_loss: 0.5568 - val_accuracy: 0.7268\n",
            "Epoch 60/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5489 - accuracy: 0.7354 - val_loss: 0.5551 - val_accuracy: 0.7273\n",
            "Epoch 61/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5474 - accuracy: 0.7349 - val_loss: 0.5564 - val_accuracy: 0.7280\n",
            "Epoch 62/100\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5484 - accuracy: 0.7345 - val_loss: 0.5566 - val_accuracy: 0.7264\n",
            "Epoch 63/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5486 - accuracy: 0.7343 - val_loss: 0.5556 - val_accuracy: 0.7275\n",
            "Epoch 64/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5480 - accuracy: 0.7354 - val_loss: 0.5549 - val_accuracy: 0.7284\n",
            "Epoch 65/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5490 - accuracy: 0.7344 - val_loss: 0.5560 - val_accuracy: 0.7276\n",
            "Epoch 66/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5468 - accuracy: 0.7362 - val_loss: 0.5551 - val_accuracy: 0.7276\n",
            "Epoch 67/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5483 - accuracy: 0.7356 - val_loss: 0.5573 - val_accuracy: 0.7277\n",
            "Epoch 68/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5478 - accuracy: 0.7338 - val_loss: 0.5559 - val_accuracy: 0.7251\n",
            "Epoch 69/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5484 - accuracy: 0.7341 - val_loss: 0.5562 - val_accuracy: 0.7264\n",
            "Epoch 70/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5469 - accuracy: 0.7348 - val_loss: 0.5559 - val_accuracy: 0.7278\n",
            "Epoch 71/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5479 - accuracy: 0.7346 - val_loss: 0.5563 - val_accuracy: 0.7290\n",
            "Epoch 72/100\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5479 - accuracy: 0.7355 - val_loss: 0.5550 - val_accuracy: 0.7283\n",
            "Epoch 73/100\n",
            "573/804 [====================>.........] - ETA: 0s - loss: 0.5487 - accuracy: 0.7362"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-02309d5e23e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         tuner_utils.validate_trial_results(\n\u001b[1;32m    224\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HyperModel.fit()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \"\"\"\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "tuner.search(X_train_scaled, y_train, epochs=100, validation_data=(X_test_scaled,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pull best hyperparameters\n",
        "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
        "best_hp.values\n"
      ],
      "metadata": {
        "id": "otkSxIpnDEgB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e727491-34a0-403d-cf4c-8bb20e252615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'tanh',\n",
              " 'first_dense': 9,\n",
              " 'n_hidden': 2,\n",
              " 'dense_0': 8,\n",
              " 'dropout_0': 0.1,\n",
              " 'dense_1': 4,\n",
              " 'dropout_1': 0.1}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = tuner.get_best_models(1)[0]\n",
        "model_loss, model_accuracy = best_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zbg5eFd0VFdg",
        "outputId": "364e81ea-94f2-4a56-b46a-1c92648bc578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 1s - loss: 0.5557 - accuracy: 0.7315 - 615ms/epoch - 2ms/step\n",
            "Loss: 0.5556725263595581, Accuracy: 0.7315452098846436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the top hyperparameters.\n",
        "best_hps = tuner.get_best_hyperparameters(2)\n",
        "# Build the model with the best hp.\n",
        "model = make_model(best_hps[0])\n",
        "# Fit with the entire dataset.\n",
        "x_all = np.concatenate((X_train_scaled, X_test_scaled))\n",
        "y_all = np.concatenate((y_train, y_test))\n",
        "model.fit(x=x_all, y=y_all, epochs=100)"
      ],
      "metadata": {
        "id": "e7Re4Bgobs-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.save('hp_model')\n",
        "best_model.save('hp_model.h5')\n"
      ],
      "metadata": {
        "id": "md5PqZJzYyHd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "3f8e71100435e7bad3de0247326fe2ee2f66761e6a4d6a3e4c67b492e2c5904b"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}